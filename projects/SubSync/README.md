
# OpenAI ASR - Accurate and Fast Audio and Video Transcription Tool for Bulk Processing of Multiple Files

[GNU GENERAL PUBLIC LICENSE](https://www.gnu.org/licenses/gpl-3.0.en.html)

Transcribe all audio and video files in a directory and its subdirectories, including nested folders, with unparalleled accuracy and speed using OpenAI's Whisper ASR API. This tool can automatically transcribe audio and video formats, including mp3, mp4, mpeg, mpga, m4a, wav, and webm, and generate transcripts in text, VTT, and SRT in 50 languages with just one API call per file.

It's a Python script designed to process multiple files in bulk and can transcribe various audio and video file extensions. Our tool can traverse all folders within a directory, making it easy to transcribe large numbers of files at once.

Whisper is an Automatic Speech Recognition (ASR) system developed by OpenAI, capable of converting spoken language into written text. Learn more about the Whisper ASR API and its features [here](https://openai.com/research/whisper).




- ## TL;DR - Quick Start Guide 
1. **Install the required packages**: To get started, install packages using requirements.txt, or just open your terminal and run:

```bash

pip install webvtt-py argparse openai av requests retry moviepy imageio_ffmpeg

``` 
2. **API Key Setup**: If the not found in text file or system environment, the script will prompt you to enter the *OpenAI API key*. Just follow the instructions on the screen. 
3. **Transcribe Audio/Video**: To transcribe the audio or video files in a folder, simply run the script and provide the folder path:

```bash

python transcribe.py /path/to/your/folder
``` 
4. **Profit** : Sit back and relax! The script will generate transcripts and save them as TXT, VTT, and SRT files in the same folder as the original files. Enjoy your transcriptions!

For advanced usage and customization options, please refer to the full documentation.

## Table of Contents

- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Support for Over 50 Languages](#supported-languages)
- [How to Process Large Files](#processing-large-files)
- [Similar Audio and Video Transcription Projects](#similar-projects)
- [Overview of the Code Structure](#overview-of-the-code-structure)
- [Contribution Ideas](#contribution-ideas)
- [License](#license)


## Features
- Transcribe audio and video files using OpenAI's Audio API 
- Convert transcripts to `.txt`, `.vtt`, and `.srt` formats
- Skips files that have already been processed, based on their corresponding transcript files
- Skip files that are too large (greater than 25MB)
- Extract audio from video files before transcription (for video files with audio streams)
- Retry API calls in case of temporary failures
- Generate transcripts for multiple files in a given folder
## Usage 
1. Install the required packages: `pip install -r requirements.txt`
2. Set up an OpenAI account and generate an API key 
3. Create a `.env` file in the root directory with your OpenAI API key:


```makefile

OPENAI_API_KEY=your-api-key-here
``` 
4. Run the script with the desired arguments:

```bash

python transcribe.py /path/to/folder --formats txt vtt srt -t
```

 
- `/path/to/folder`: The path to the folder containing the audio and video files to be transcribed 
- `--formats`: Optional. The subtitle formats to generate. Multiple formats can be specified. Available choices are txt, vtt, srt. Default: txt, vtt, srt. 
- `-o`: Optional. The overwrite behavior. 'none' to skip if any file exists, 'one' to skip if all files exist, and 'all' to overwrite files. Default: 'none'. 
- `-t`: Optional. Print the transcript generated by OpenAI API. 
- `--api-key`: Optional. The path to the file containing your OpenAI API key. Default: 'openai_api_key.txt'. 
- `--timeout`: Optional. Timeout in seconds for the OpenAI API requests. Default: 600.
## Example

To transcribe all audio and video files in the folder `/path/to/folder` and generate `.txt`, `.vtt`, and `.srt` files:

```css

python transcribe.py /path/to/folder --formats txt vtt srt
```



This will transcribe all valid audio and video files in the folder `/path/to/folder` and generate `.txt`, `.vtt`, and `.srt` files for each file.

To transcribe a single audio file `audio.wav` and generate only `.txt` and `.vtt` files:

```css

python transcribe.py /path/to/folder/audio.wav --formats txt vtt
```



This will transcribe `audio.wav` and generate `.txt` and `.vtt` files for it.

## Requirements
- Python 3.6 or higher
- Python packages:
 - **openai** Python package
 - **av** Python package
 - **moviepy** Python package
 - **retry** Python package
- An API key for **OpenAI's API key** to use Whisper ASR API

## Installation
1. Clone this repository:

```bash
git clone https://github.com/granin/OpenAIASR.git
cd OpenAIASR
```


1. Install the required Python packages:

```bash

pip install -r requirements.txt
```

 

## API Key Configuration

There are four ways to provide the API key for OpenAI's Whisper ASR API to the script:

* Save the API key in a file named `openai_api_key.txt` in the project directory.
* Set the API key as an environment variable named `OPENAI_API_KEY`. For example, in your terminal, you can run:

```bash
export OPENAI_API_KEY=your_api_key_here
```

 
* Provide the API key as a command-line argument using the `-k` or `--api-key` option:

```bash

python transcribe.py -k your_api_key_here /path/to/your/folder
```

 
* If the API key is not found using any of the above methods, the script will prompt you to enter the API key on the first run. The key will be saved in the `openai_api_key.txt` file in the project directory for future use.

The script will first look for the API key in the `openai_api_key.txt` file. If the file is not found, it will look for the `OPENAI_API_KEY` environment variable. If the environment variable is not found, it will check for a command-line argument. Finally, if the command-line argument is not provided, the script will prompt the user for the API key on the first run.


## Usage

To transcribe the audio and video files in a specified folder, run the following command:

```bash

python transcribe.py /path/to/your/folder
```



By default, the script generates TXT, VTT, and SRT subtitle files. To customize the output formats, use the -f or --formats option, followed by the desired formats:

```bash

python transcribe.py -f txt srt /path/to/your/folder
```



To change the overwrite behavior, use the -o or --overwrite option:

```bash

python transcribe.py -o all /path/to/your/folder
```



To print the transcript generated by the OpenAI API, use the -t or --transcript option:

```bash

python transcribe.py -t /path/to/your/folder
```



For additional help, run:

```bash

python transcribe.py -h
```


## Support for Over 50 Languages

The Whisper ASR API currently supports the following languages:

Afrikaans, Arabic, Armenian, Azerbaijani, Belarusian, Bosnian, Bulgarian, Catalan, Chinese, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Greek, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Italian, Japanese, Kannada, Kazakh, Korean, Latvian, Lithuanian, Macedonian, Malay, Marathi, Maori, Nepali, Norwegian, Persian, Polish, Portuguese, Romanian, Russian, Serbian, Slovak, Slovenian, Spanish, Swahili, Swedish, Tagalog, Tamil, Thai, Turkish, Ukrainian, Urdu, Vietnamese, and Welsh.
## How to Process Large Files

For handling large files (greater than 25 MB), you'll need to split them into smaller chunks. One way to do this is by using the PyDub open-source Python package. To learn more about PyDub, visit [here](https://github.com/jiaaro/pydub).

Note: Authors & OpenAI makes no guarantees about the usability or security of 3rd party software like PyDub.

Here's an example of how to use PyDub to split an audio file into smaller chunks:

```python

from pydub import AudioSegment

song = AudioSegment.from_mp3("long_audio.mp3")

# PyDub handles time in milliseconds
thirty_minutes = 30 * 60 * 1000

first_30_minutes = song[:thirty_minutes]

first_30_minutes.export("long_audio_30.mp3", format="mp3")

```

## Similar Audio and Video Transcription Projects

Here are some similar projects related to audio and video transcription: 

### Open-Source Projects (with MIT or similar licenses) 
- [autosub](https://github.com/agermanidis/autosub): A command-line utility for automatic speech recognition and subtitle generation. (MIT License) 
- [Vosk-API](https://github.com/alphacep/vosk-api) : An offline speech recognition API for 20+ languages with support for custom language models. (Apache License 2.0) 
- [DeepSpeech](https://github.com/mozilla/DeepSpeech): A speech-to-text engine by Mozilla, using a model trained by machine learning techniques based on Baidu's Deep Speech research paper. (Mozilla Public License 2.0)

### Other Projects

3. [DeepSpeech](https://github.com/mozilla/DeepSpeech): A speech-to-text engine by Mozilla, using a model trained by machine learning techniques based on Baidu's Deep Speech research paper. 
4. [AssemblyAI](https://www.assemblyai.com/): A transcription service offering an API for transcribing audio and video files using their automatic speech recognition technology. 
5. [Google Speech-to-Text](https://cloud.google.com/speech-to-text): A cloud-based API from Google for converting spoken language into written text. 
6. [IBM Watson Speech to Text](https://www.ibm.com/cloud/watson-speech-to-text): A cloud-based API from IBM Watson for converting speech into text with support for various languages and real-time recognition.

Note that these projects may have different licensing, pricing, and capabilities. Be sure to review their documentation and licenses before using them.
 ## Overview of the code structure
### Import Libraries

The script begins with importing several libraries. These libraries provide file I/O, audio and video processing, and API requests.
### Define Custom Exception

A custom exception **APIError**  is defined to handle errors during API requests.
### Define Decorator

A **retry**  decorator is defined that retries a function multiple times with a delay in case of errors.
### Define Validation Functions

Two validation functions are defined to check whether a given file **path contains audio or video**  content and whether the **file size is valid per API**  restrictions.
### Define Conversion Functions

Conversion functions are defined to **convert file sizes**  to megabytes and **convert VTT subtitle format to SRT**  subtitle format.
### Define API Functions

Three functions are defined that handle API requests to the OpenAI audio transcription API. The first function **transcribes audio using the OpenAI API** , the second function **generates subtitles**  in the specified format, and the third function **transcribes audio and saves the resulting subtitles**  in the specified format.
### Define Processing Functions

Several processing functions are defined to perform audio and video processing tasks, such as **extracting audio from video**  files, generating **subtitles in multiple formats** , and **saving the resulting subtitles to disk** .
### Define Main Function

The main function processes audio and video files in the specified folder path and generates subtitles in the specified formats. It first **loads the OpenAI API key**  from the system environment or specified file or prompts the user to enter it. It then **processes each audio or video file**  in the folder path, skipping files that have already been processed or do not meet the validation criteria. Finally, it **generates subtitles**  in the specified formats and saves them to disk.
### Define Command Line Arguments

Several command line **arguments**  are defined to specify the **folder path, subtitle formats, overwrite behavior** , and other parameters used by the main function.
### Configure Logging

The script configures logging to provide information on the status of the transcription process.

## Contribution Ideas 
- **Processing Large Files:** The project currently doesn't support large files greater than 25 MB. One way to handle this is by splitting them into smaller chunks using the PyDub open-source Python package. Contributions are welcome to help implement this feature. 
- **Prompting Techniques:** Prompting can improve the quality of the transcripts generated by our Whisper API. Contributions are welcome to develop more advanced prompting techniques. 
- **Measuring API Usage:** To better understand how OpenAI API is being used, we need a way to measure API usage. Contributions are welcome to help develop tools for measuring API usage and analyzing usage data. 
- **Testing and Bug Fixes:** Contributions are welcome to help test and fix bugs to ensure that our software is running smoothly and efficiently. 
- **Documentation:** Contributions are welcome to improve this documentation, including adding examples and tutorials that make it easier for users to get started with our project. 
- **Feature Requests:** If you have any ideas for new features that you'd like to see in our project, please let us know! Contributions are welcome, and we're always open to new ideas and suggestions.


We welcome contributions from anyone interested in our project, regardless of their skill level or experience. If you're new to open-source software development, we'll be happy to help you get started. Additionally, contributions are subject to the project's license and code of conduct.

## License

This project is licensed under the [MIT License](https://chat.openai.com/LICENSE).

