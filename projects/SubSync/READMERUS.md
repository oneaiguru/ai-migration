
# Система распознавания речи OpenAI (ASR) - Точный и быстрый инструмент транскрипции аудио и видео для массовой обработки нескольких файлов

[GNU GENERAL PUBLIC LICENSE](https://www.gnu.org/licenses/gpl-3.0.en.html)

Расшифруйте все аудио- и видеофайлы в каталоге и его подкаталогах, включая вложенные папки, с непревзойденной точностью и скоростью, используя API Whisper ASR от OpenAI. Этот инструмент может автоматически транскрибировать аудио и видео форматы, включая mp3, mp4, mpeg, mpga, m4a, wav и webm, и генерировать транскрипты в виде текста, VTT и SRT на 50 языках с помощью всего одного вызова API для каждого файла.

Это скрипт на языке Python, предназначенный для массовой обработки нескольких файлов и способный расшифровывать аудио- и видеофайлы различных расширений. Наш инструмент может обходить все папки в каталоге, что упрощает одновременную расшифровку большого количества файлов.

Whisper - это система автоматического распознавания речи (ASR), разработанная OpenAI, способная преобразовывать устную речь в письменный текст. Подробнее об API Whisper ASR и его возможностях [здесь] (https://openai.com/research/whisper).




- ## TL;DR - Краткое руководство пользователя 

1. **Установите необходимые пакеты**: Для начала работы установите пакеты, используя файл requirements.txt, или просто откройте терминал и запустите:

```bash

pip install webvtt-py argparse openai av requests retry moviepy imageio_ffmpeg

``` 

2. **Настройка ключей API**: Если ключ не найден в текстовом файле или в системном окружении, скрипт предложит вам ввести *ключ API OpenAI*. Просто следуйте инструкциям на экране. 

3. **Транскрибировать аудио/видео**: Чтобы расшифровать аудио- или видеофайлы в папке, просто запустите скрипт и укажите путь к папке:

```bash

python transcribe.py /path/to/your/folder
``` 
4. **Прибыль** : Сядьте поудобнее и расслабьтесь! Скрипт создаст транскрипты и сохранит их в виде файлов TXT, VTT и SRT в той же папке, что и исходные файлы. Наслаждайтесь своими транскрипциями!

О расширенных возможностях использования и настройки, пожалуйста, обратитесь к полной документации.



## Особенности
- Расшифровка аудио- и видеофайлов с использованием OpenAI's Audio API 
- Преобразование транскриптов в форматы `.txt`, `.vtt` и `.srt`.
- Пропускает файлы, которые уже были обработаны, основываясь на соответствующих файлах транскриптов
- Пропускать слишком большие файлы (более 25 МБ)
- Извлекает аудио из видеофайлов перед транскрипцией (для видеофайлов с аудиопотоками)
- Повторные вызовы API в случае временных сбоев
- Генерировать транскрипты для нескольких файлов в заданной папке.
## Использование 
1. Установите необходимые пакеты: `pip install -r requirements.txt`.
2. Создайте учетную запись OpenAI и сгенерируйте API-ключ. 
3. Создайте файл `.env` в корневом каталоге с ключом API OpenAI:


```makefile

OPENAI_API_KEY=ваш-api-key-здесь
``` 
4. Запустите скрипт с нужными аргументами:

```css

python transcribe.py /path/to/folder --formats txt vtt srt -t
```

 
- `/path/to/folder`: Путь к папке, содержащей аудио- и видеофайлы для транскрибирования. 
- `--форматы`: Необязательно. Форматы субтитров для генерации. Можно указать несколько форматов. Доступны следующие варианты: txt, vtt, srt. По умолчанию: txt, vtt, srt. 
- `-o`: Необязательно. Поведение при перезаписи. 'none' - пропускать, если существует какой-либо файл, 'one' - пропускать, если существуют все файлы, и 'all' - перезаписывать файлы. По умолчанию: 'none'. 
- `-t`: Необязательно. Вывести транскрипт, созданный OpenAI API. 
- `--api-key`: Необязательно. Путь к файлу, содержащему ваш ключ OpenAI API. По умолчанию: 'openai_api_key.txt'. 
- `--timeout`: Необязательно. Таймаут в секундах для запросов OpenAI API. По умолчанию: 600.
## Пример

Для расшифровки всех аудио- и видеофайлов в папке `/path/to/folder` и создания файлов `.txt`, `.vtt` и `.srt`:

```css

python transcribe.py /path/to/folder --formats txt vtt srt
```



Это расшифрует все допустимые аудио и видео файлы в папке `/path/to/folder` и создаст файлы `.txt`, `.vtt` и `.srt` для каждого файла.

Чтобы расшифровать один аудиофайл `audio.wav` и создать только файлы `.txt` и `.vtt`:

```css

python transcribe.py /path/to/folder/audio.wav --formats txt vtt
```



Это расшифрует `audio.wav` и создаст для него файлы `.txt` и `.vtt`.

## Требования
- Python 3.6 или выше
- Пакеты Python:
 - **openai** Python пакет.
 - **av** Python пакет
 - **moviepy** Python пакет
 - **retry** Python пакет
- API-ключ **OpenAI's API key** для использования Whisper ASR API

## Установка
1. Клонируйте этот репозиторий:

```bash
git clone https://github.com/granin/OpenAIASR.git
cd OpenAIASR
```


1. Установите необходимые пакеты Python:

```bash

pip install -r requirements.txt
```

 


## Конфигурация ключа API

Существует четыре способа предоставить скрипту ключ API для API Whisper ASR от OpenAI:

* Сохранить ключ API в файле с именем `openai_api_key.txt` в директории проекта.
* Установите ключ API в качестве переменной окружения с именем `OPENAI_API_KEY`. Например, в терминале вы можете выполнить:


```

export OPENAI_API_KEY=ваш_api_ключ_здесь

```

 
* Предоставьте ключ API в качестве аргумента командной строки, используя опцию `-k` или `--api-key`:


```

python transcribe.py -k your_api_key_here /path/to/your/folder

```

 
* Если ключ API не найден ни одним из вышеперечисленных способов, скрипт предложит вам ввести ключ API при первом запуске. Ключ будет сохранен в файле `openai_api_key.txt` в директории проекта для дальнейшего использования.

Сначала скрипт будет искать ключ API в файле `openai_api_key.txt`. Если файл не найден, он будет искать переменную окружения `OPENAI_API_KEY`. Если переменная окружения не найдена, будет проверен аргумент командной строки. Наконец, если аргумент командной строки не указан, скрипт запросит у пользователя ключ API при первом запуске.


## Использование

Чтобы расшифровать аудио- и видеофайлы в указанной папке, выполните следующую команду:

```

python transcribe.py /path/to/ваша/папка

```


По умолчанию скрипт генерирует файлы субтитров TXT, VTT и SRT. Чтобы настроить выходные форматы, используйте опцию -f или --formats, а затем нужные форматы:


```

python transcribe.py -f txt srt /path/to/your/folder

```



Чтобы изменить поведение перезаписи, используйте опцию -o или --overwrite:


```

python transcribe.py -o all /path/to/your/folder

```



Чтобы распечатать транскрипт, созданный OpenAI API, используйте опцию -t или --transcript:


```

python transcribe.py -t /path/to/your/folder

```



Для получения дополнительной помощи выполните:


```

python transcribe.py -h

```


## Поддержка более 50 языков

В настоящее время API ASR Whisper поддерживает следующие языки:

Африканский, арабский, армянский, азербайджанский, белорусский, боснийский, болгарский, каталанский, китайский, хорватский, чешский, датский, голландский, английский, эстонский, финский, французский, галисийский, немецкий, греческий, иврит, хинди, венгерский, исландский, индонезийский, итальянский, японский, каннада, казахский, корейский, латышский, литовский, македонский, малайский, маратхи, маори, непали, норвежский, персидский, польский, португальский, румынский, русский, сербский, словацкий, словенский, испанский, суахили, шведский, тагальский, тамильский, тайский, турецкий, украинский, урду, вьетнамский и валлийский.
## Как обрабатывать большие файлы

Для обработки больших файлов (более 25 МБ) вам потребуется разделить их на более мелкие фрагменты. Один из способов сделать это - использовать пакет PyDub с открытым исходным кодом Python. Чтобы узнать больше о PyDub, посетите [здесь](https://github.com/jiaaro/pydub).

Примечание: Authors & OpenAI не дает никаких гарантий относительно удобства использования или безопасности программного обеспечения сторонних производителей, такого как PyDub.

Вот пример того, как использовать PyDub для разделения аудиофайла на более мелкие фрагменты:

```python

from pydub import AudioSegment

song = AudioSegment.from_mp3("long_audio.mp3")

# PyDub обрабатывает время в миллисекундах
тридцать_минут = 30 * 60 * 1000

first_30_minutes = song[:thirty_minutes]

first_30_minutes.export("long_audio_30.mp3", format="mp3")

```

## Похожие проекты по транскрипции аудио и видео

Вот некоторые похожие проекты, связанные с транскрипцией аудио и видео: 

### Проекты с открытым исходным кодом (с лицензией MIT или аналогичной) 
- [autosub](https://github.com/agermanidis/autosub): Утилита командной строки для автоматического распознавания речи и создания субтитров. (Лицензия MIT) 
- [Vosk-API](https://github.com/alphacep/vosk-api) : API для автономного распознавания речи для 20+ языков с поддержкой пользовательских языковых моделей. (Лицензия Apache 2.0) 
- [DeepSpeech](https://github.com/mozilla/DeepSpeech): Механизм преобразования речи в текст от Mozilla, использующий модель, обученную методами машинного обучения на основе научной работы Baidu Deep Speech. (Общественная лицензия Mozilla 2.0)

### Другие проекты

3. [DeepSpeech](https://github.com/mozilla/DeepSpeech): Механизм преобразования речи в текст от Mozilla, использующий модель, обученную методами машинного обучения на основе научной работы Baidu Deep Speech. 
4. [AssemblyAI](https://www.assemblyai.com/): Сервис транскрипции, предлагающий API для транскрибирования аудио- и видеофайлов с помощью своей технологии автоматического распознавания речи. 
5. [Google Speech-to-Text](https://cloud.google.com/speech-to-text): Облачный API от Google для преобразования устной речи в письменный текст. 
6. [IBM Watson Speech to Text](https://www.ibm.com/cloud/watson-speech-to-text): Облачный API от IBM Watson для преобразования речи в текст с поддержкой различных языков и распознаванием в реальном времени.

Обратите внимание, что эти проекты могут иметь разное лицензирование, цены и возможности. Перед использованием обязательно ознакомьтесь с их документацией и лицензиями.
 